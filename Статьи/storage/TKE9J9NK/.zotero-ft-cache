
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2301.03118

Help | Advanced Search
Search
Computer Science > Cryptography and Security
(cs)
[Submitted on 8 Jan 2023]
Title: Facial Misrecognition Systems: Simple Weight Manipulations Force DNNs to Err Only on Specific Persons
Authors: Irad Zehavi , Adi Shamir
Download a PDF of the paper titled Facial Misrecognition Systems: Simple Weight Manipulations Force DNNs to Err Only on Specific Persons, by Irad Zehavi and 1 other authors
Download PDF

    Abstract: In this paper we describe how to plant novel types of backdoors in any facial recognition model based on the popular architecture of deep Siamese neural networks, by mathematically changing a small fraction of its weights (i.e., without using any additional training or optimization). These backdoors force the system to err only on specific persons which are preselected by the attacker. For example, we show how such a backdoored system can take any two images of a particular person and decide that they represent different persons (an anonymity attack), or take any two images of a particular pair of persons and decide that they represent the same person (a confusion attack), with almost no effect on the correctness of its decisions for other persons. Uniquely, we show that multiple backdoors can be independently installed by multiple attackers who may not be aware of each other's existence with almost no interference.
    We have experimentally verified the attacks on a FaceNet-based facial recognition system, which achieves SOTA accuracy on the standard LFW dataset of 99.35 % . When we tried to individually anonymize ten celebrities, the network failed to recognize two of their images as being the same person in 96.97 % to 98.29 % of the time. When we tried to confuse between the extremely different looking Morgan Freeman and Scarlett Johansson, for example, their images were declared to be the same person in 91.51 % of the time. For each type of backdoor, we sequentially installed multiple backdoors with minimal effect on the performance of each one (for example, anonymizing all ten celebrities on the same model reduced the success rate for each celebrity by no more than 0.91 % ). In all of our experiments, the benign accuracy of the network on other persons was degraded by no more than 0.48 % (and in most cases, it remained above 99.30 % ). 

Subjects: 	Cryptography and Security (cs.CR) ; Machine Learning (cs.LG)
Cite as: 	arXiv:2301.03118 [cs.CR]
  	(or arXiv:2301.03118v1 [cs.CR] for this version)
  	https://doi.org/10.48550/arXiv.2301.03118
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Irad Zehavi [ view email ]
[v1] Sun, 8 Jan 2023 23:11:00 UTC (1,167 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Facial Misrecognition Systems: Simple Weight Manipulations Force DNNs to Err Only on Specific Persons, by Irad Zehavi and 1 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CR
< prev   |   next >
new | recent | 2301
Change to browse by:
cs
cs.LG
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

