
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2305.18651

Help | Advanced Search
Search
Computer Science > Machine Learning
(cs)
[Submitted on 29 May 2023 ( v1 ), last revised 2 Jun 2023 (this version, v2)]
Title: UMD: Unsupervised Model Detection for X2X Backdoor Attacks
Authors: Zhen Xiang , Zidi Xiong , Bo Li
Download a PDF of the paper titled UMD: Unsupervised Model Detection for X2X Backdoor Attacks, by Zhen Xiang and 2 other authors
Download PDF

    Abstract: Backdoor (Trojan) attack is a common threat to deep neural networks, where samples from one or more source classes embedded with a backdoor trigger will be misclassified to adversarial target classes. Existing methods for detecting whether a classifier is backdoor attacked are mostly designed for attacks with a single adversarial target (e.g., all-to-one attack). To the best of our knowledge, without supervision, no existing methods can effectively address the more general X2X attack with an arbitrary number of source classes, each paired with an arbitrary target class. In this paper, we propose UMD, the first Unsupervised Model Detection method that effectively detects X2X backdoor attacks via a joint inference of the adversarial (source, target) class pairs. In particular, we first define a novel transferability statistic to measure and select a subset of putative backdoor class pairs based on a proposed clustering approach. Then, these selected class pairs are jointly assessed based on an aggregation of their reverse-engineered trigger size for detection inference, using a robust and unsupervised anomaly detector we proposed. We conduct comprehensive evaluations on CIFAR-10, GTSRB, and Imagenette dataset, and show that our unsupervised UMD outperforms SOTA detectors (even with supervision) by 17%, 4%, and 8%, respectively, in terms of the detection accuracy against diverse X2X attacks. We also show the strong detection performance of UMD against several strong adaptive attacks. 

Comments: 	ICML 2023
Subjects: 	Machine Learning (cs.LG) ; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2305.18651 [cs.LG]
  	(or arXiv:2305.18651v2 [cs.LG] for this version)
  	https://doi.org/10.48550/arXiv.2305.18651
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Zhen Xiang [ view email ]
[v1] Mon, 29 May 2023 23:06:05 UTC (1,029 KB)
[v2] Fri, 2 Jun 2023 01:56:40 UTC (1,029 KB)
Full-text links:
Download:

    Download a PDF of the paper titled UMD: Unsupervised Model Detection for X2X Backdoor Attacks, by Zhen Xiang and 2 other authors
    PDF
    Other formats 

Current browse context:
cs.LG
< prev   |   next >
new | recent | 2305
Change to browse by:
cs
cs.CR
cs.CV
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

