
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2305.10596

Help | Advanced Search
Search
Computer Science > Cryptography and Security
(cs)
[Submitted on 10 May 2023]
Title: Towards Invisible Backdoor Attacks in the Frequency Domain against Deep Neural Networks
Authors: Xinrui Liu , Yajie Wang , Yu-an Tan , Kefan Qiu , Yuanzhang Li
Download a PDF of the paper titled Towards Invisible Backdoor Attacks in the Frequency Domain against Deep Neural Networks, by Xinrui Liu and 4 other authors
Download PDF

    Abstract: Deep neural networks (DNNs) have made tremendous progress in the past ten years and have been applied in various critical applications. However, recent studies have shown that deep neural networks are vulnerable to backdoor attacks. By injecting malicious data into the training set, an adversary can plant the backdoor into the original model. The backdoor can remain hidden indefinitely until activated by a sample with a specific trigger, which is hugely concealed, bringing serious security risks to critical applications. However, one main limitation of current backdoor attacks is that the trigger is often visible to human perception. Therefore, it is crucial to study the stealthiness of backdoor triggers. In this paper, we propose a novel frequency-domain backdooring technique. In particular, our method aims to add a backdoor trigger in the frequency domain of original images via Discrete Fourier Transform, thus hidding the trigger. We evaluate our method on three benchmark datasets: MNIST, CIFAR-10 and Imagenette. Our experiments show that we can simultaneously fool human inspection and DNN models. We further apply two image similarity evaluation metrics to illustrate that our method adds the most subtle perturbation without compromising attack success rate and clean sample accuracy. 

Comments: 	arXiv admin note: text overlap with arXiv:2305.09677
Subjects: 	Cryptography and Security (cs.CR)
Cite as: 	arXiv:2305.10596 [cs.CR]
  	(or arXiv:2305.10596v1 [cs.CR] for this version)
  	https://doi.org/10.48550/arXiv.2305.10596
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Xinrui Liu [ view email ]
[v1] Wed, 10 May 2023 09:09:56 UTC (8,664 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Towards Invisible Backdoor Attacks in the Frequency Domain against Deep Neural Networks, by Xinrui Liu and 4 other authors
    PDF
    Other formats 

Current browse context:
cs.CR
< prev   |   next >
new | recent | 2305
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

