
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2307.11565

Help | Advanced Search
Search
Computer Science > Machine Learning
(cs)
[Submitted on 21 Jul 2023]
Title: FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks
Authors: Dong Huang , Qingwen Bu , Yahao Qing , Yichao Fu , Heming Cui
Download a PDF of the paper titled FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks, by Dong Huang and 4 other authors
Download PDF

    Abstract: Deep neural networks have been widely used in many critical applications, such as autonomous vehicles and medical diagnosis. However, their security is threatened by backdoor attack, which is achieved by adding artificial patterns to specific training data. Existing defense strategies primarily focus on using reverse engineering to reproduce the backdoor trigger generated by attackers and subsequently repair the DNN model by adding the trigger into inputs and fine-tuning the model with ground-truth labels. However, once the trigger generated by the attackers is complex and invisible, the defender can not successfully reproduce the trigger. Consequently, the DNN model will not be repaired since the trigger is not effectively removed.
    In this work, we propose Feature Map Testing~(FMT). Different from existing defense strategies, which focus on reproducing backdoor triggers, FMT tries to detect the backdoor feature maps, which are trained to extract backdoor information from the inputs. After detecting these backdoor feature maps, FMT will erase them and then fine-tune the model with a secure subset of training data. Our experiments demonstrate that, compared to existing defense strategies, FMT can effectively reduce the Attack Success Rate (ASR) even against the most complex and invisible attack triggers. Second, unlike conventional defense methods that tend to exhibit low Robust Accuracy (i.e., the model's accuracy on the poisoned data), FMT achieves higher RA, indicating its superiority in maintaining model performance while mitigating the effects of backdoor attacks~(e.g., FMT obtains 87.40\% RA in CIFAR10). Third, compared to existing feature map pruning techniques, FMT can cover more backdoor feature maps~(e.g., FMT removes 83.33\% of backdoor feature maps from the model in the CIFAR10 \& BadNet scenario). 

Comments: 	12 pages, 4 figures
Subjects: 	Machine Learning (cs.LG) ; Software Engineering (cs.SE)
Cite as: 	arXiv:2307.11565 [cs.LG]
  	(or arXiv:2307.11565v1 [cs.LG] for this version)
  	https://doi.org/10.48550/arXiv.2307.11565
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Qingwen Bu [ view email ]
[v1] Fri, 21 Jul 2023 13:17:22 UTC (730 KB)
Full-text links:
Download:

    Download a PDF of the paper titled FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks, by Dong Huang and 4 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.LG
< prev   |   next >
new | recent | 2307
Change to browse by:
cs
cs.SE
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

