
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2303.12993

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 23 Mar 2023]
Title: Backdoor Defense via Adaptively Splitting Poisoned Dataset
Authors: Kuofeng Gao , Yang Bai , Jindong Gu , Yong Yang , Shu-Tao Xia
Download a PDF of the paper titled Backdoor Defense via Adaptively Splitting Poisoned Dataset, by Kuofeng Gao and 4 other authors
Download PDF

    Abstract: Backdoor defenses have been studied to alleviate the threat of deep neural networks (DNNs) being backdoor attacked and thus maliciously altered. Since DNNs usually adopt some external training data from an untrusted third party, a robust backdoor defense strategy during the training stage is of importance. We argue that the core of training-time defense is to select poisoned samples and to handle them properly. In this work, we summarize the training-time defenses from a unified framework as splitting the poisoned dataset into two data pools. Under our framework, we propose an adaptively splitting dataset-based defense (ASD). Concretely, we apply loss-guided split and meta-learning-inspired split to dynamically update two data pools. With the split clean data pool and polluted data pool, ASD successfully defends against backdoor attacks during training. Extensive experiments on multiple benchmark datasets and DNN models against six state-of-the-art backdoor attacks demonstrate the superiority of our ASD. Our code is available at this https URL . 

Comments: 	Accepted by CVPR 2023
Subjects: 	Computer Vision and Pattern Recognition (cs.CV) ; Cryptography and Security (cs.CR)
Cite as: 	arXiv:2303.12993 [cs.CV]
  	(or arXiv:2303.12993v1 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2303.12993
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Kuofeng Gao [ view email ]
[v1] Thu, 23 Mar 2023 02:16:38 UTC (5,587 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Backdoor Defense via Adaptively Splitting Poisoned Dataset, by Kuofeng Gao and 4 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CV
< prev   |   next >
new | recent | 2303
Change to browse by:
cs
cs.CR
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

