
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2205.06900

Help | Advanced Search
Search
Computer Science > Machine Learning
(cs)
[Submitted on 13 May 2022]
Title: Universal Post-Training Backdoor Detection
Authors: Hang Wang , Zhen Xiang , David J. Miller , George Kesidis
Download a PDF of the paper titled Universal Post-Training Backdoor Detection, by Hang Wang and 3 other authors
Download PDF

    Abstract: A Backdoor attack (BA) is an important type of adversarial attack against deep neural network classifiers, wherein test samples from one or more source classes will be (mis)classified to the attacker's target class when a backdoor pattern (BP) is embedded. In this paper, we focus on the post-training backdoor defense scenario commonly considered in the literature, where the defender aims to detect whether a trained classifier was backdoor attacked, without any access to the training set. To the best of our knowledge, existing post-training backdoor defenses are all designed for BAs with presumed BP types, where each BP type has a specific embedding function. They may fail when the actual BP type used by the attacker (unknown to the defender) is different from the BP type assumed by the defender. In contrast, we propose a universal post-training defense that detects BAs with arbitrary types of BPs, without making any assumptions about the BP type. Our detector leverages the influence of the BA, independently of the BP type, on the landscape of the classifier's outputs prior to the softmax layer. For each class, a maximum margin statistic is estimated using a set of random vectors; detection inference is then performed by applying an unsupervised anomaly detector to these statistics. Thus, our detector is also an advance relative to most existing post-training methods by not needing any legitimate clean samples, and can efficiently detect BAs with arbitrary numbers of source classes. These advantages of our detector over several state-of-the-art methods are demonstrated on four datasets, for three different types of BPs, and for a variety of attack configurations. Finally, we propose a novel, general approach for BA mitigation once a detection is made. 

Subjects: 	Machine Learning (cs.LG) ; Cryptography and Security (cs.CR)
Cite as: 	arXiv:2205.06900 [cs.LG]
  	(or arXiv:2205.06900v1 [cs.LG] for this version)
  	https://doi.org/10.48550/arXiv.2205.06900
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Zhen Xiang [ view email ]
[v1] Fri, 13 May 2022 21:32:24 UTC (776 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Universal Post-Training Backdoor Detection, by Hang Wang and 3 other authors
    PDF
    Other formats 

Current browse context:
cs.LG
< prev   |   next >
new | recent | 2205
Change to browse by:
cs
cs.CR
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

